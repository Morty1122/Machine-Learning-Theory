# 1_监督学习_概要

## 统计学习：

* 监督学习
* 无监督学习
* 强化学习

主要看前两种，先研究监督学习

## 监督学习：找输入输出的映射规律

### 能用上的量：

1. 输入空间、输出空间：输入与输出的取值集合
2. 特征空间：特征向量的集合

$$
T=\{(x_1,y_1),(x_2,y_2),...,(x_N,y_N)\}
$$

3. 特征向量：$(x_1,y_1)$
4. 假设空间：学习范围，从输入到输出的空间映射
5. 损失函数：预测值与实际值的差值，非负，值越小预测效果越好
   * 0-1损失函数
   * 平方损失函数
   * 绝对损失函数
   * 对数损失函数
6. 期望风险：损失函数的期望值（期望风险，算不出来，用下面的经验风险值估计，依据：大数定律）
7. 经验风险：用$N→∞$来代替$P(Y|X)$，进一步把学习目标数字化

$$
R_{emp}(f)=\frac{1}{N}\sum_{i=1}^{N}L(y_i,f(x_i))
$$

8. 结构风险：防止过拟合，加了一项复杂度约束

$$
R_{srm}(f)=\frac{1}{N}\sum_{i=1}^{N}L(y_i,f(x_i))+\lambda J(f)
$$

tips：监督学习问题可以看成经验风险与结构风险最优化问题

9. 训练误差：训练时得到的模型的误差，（其实就是经验风险）
10. 测试误差：把样本容量变了一下而已，因为现在是测试的数据了，所以$N$变$N'$了，其他的不变

$$
e_{test}=\frac{1}{N'}\sum_{i=1}^{N'}L(y_i,\hat{f}(x_i))
$$

tips：你会发现，训练误差只是说明训练时候有多辛苦（问题容不容易学习），反应不出来你训练好的模型的预测能力，测试误差才能看出来你的预测能力

11. 泛化能力：就是对未知数据的预测能力
12. 过拟合：可以理解为，模型太熟悉你的训练样本了，以至于拼命想讨好你的训练样本，而对于未知数据的预测就细碎（学的太死了，变样不知道该干什么了）

tips：有时候你模型复杂度高了，训练误差会减小，测试误差会先减小后增大，而我们的目的是让测试误差达到最小，所以就要选择复杂度适当的模型，考虑结构风险最小化策略

13. 正则化：作用就是选择经验风险与复杂度同时较小的模型（结构风险最小化的体现，式子都跟结构风险一样）
14. 交叉验证：把数据集分成训练集、验证集、测试集，选择对验证集最小预测误差的模型，（只让他做一部分模拟卷，在验证集里面看看他的临场变通能力）

    * 简单交叉验证：一部分训练集，一部分测试集
    * $S$ 折交叉验证：拆成 $S$ 个子集，其中 $(S-1)$ 个子集训练，留下子集测试，反复测最后选出平均测试误差最小的模型
    * 留一交叉验证：取$S=N$，极限情况
15. 泛化误差：预测能力（其实就是预测准不准，与期望风险一样）

$$
R_{exp}(\hat{f})=E_P[L(Y,\hat{f}(X))] =\int_{\mathcal{X×Y}}L(y,\hat{f}(x))P(x,y)dxdy
$$

16. 泛化误差上界：衡量预测能力。直观上来看，样本容量$N$越大，能训练的样本多，这个值应该越来越小；假设空间越大（输入输出对应关系越复杂），模型越难学，这个值应该越来越大。下面从数学角度来看：

对于二类分类问题，如果假设空间有限，$\mathcal{F}=\{f_1,f_2,...,f_d\}$时，对于任意一个函数$f\in\mathcal{F}$，只要以概率$1-\delta$，$0<\delta<1$，使以下不等式成立：

$$
R(f)\leq \hat{R}(f)+\epsilon(d,N,\delta)
$$

其中，

$$
\epsilon(d,N,\delta)=\sqrt{\frac{1}{2N}\left(\rm{log} \, d+\rm{log}\,\frac{1}{\delta}\right)}
$$

这里面不等号右侧为泛化误差上界，第一项为训练误差，$N$增大时，这项会减小，泛化误差会减小。

### 整体逻辑：

刚才用了很长的篇幅梳理明白了所有要用到的量，接下来研究他们之间的关系

监督学习过程中，要先有输入空间 $\mathcal{X}$ 和输出空间 $\mathcal{Y}$ 这样就能探究他们之间的关系，从而出现假设空间 $\mathcal{F}$ 。有了模型，分析该模型的好坏，挑一种损失函数，根据经验风险最小化和结构风险最小化的策略得到合适的模型函数，接下来分析他的泛化误差，由于直接看泛化误差看不了，我们一般看泛化误差上界来判断模型好坏。再简单点罗列出来就是：

* 得到输入空间 $\mathcal{X}$ 和输出空间 $\mathcal{Y}$
* 得到假设空间 $\mathcal{F}$
* 挑选一种损失函数
* 根据经验风险最小化和结构风险最小化的策略从$\mathcal{F}$中得到最合适的模型函数$f_N$
* 用$f_N$分析泛化误差上界，看效果到底如何

### 监督学习的应用

监督学习有三种应用方面，主要也是围绕这些展开的

* 分类问题：对新的输入进行输出的预测

例如：K近邻法、感知机、朴素贝叶斯法、决策树、逻辑回归、支持向量机、提升树、神经网络、Winnow等

* 标注问题：对输入序列进行标记

例如：隐马尔可夫模型、条件随机场

* 回归问题：研究输入变化时输出变化趋势（拟合）

例如：线性回归、非线性回归

下一章我们开始研究感知机，敬请期待！
